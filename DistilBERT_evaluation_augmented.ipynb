{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"DistilBERT_evaluation_augmented.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BXyQvCqdLNAw","executionInfo":{"status":"ok","timestamp":1623334895975,"user_tz":-120,"elapsed":6116,"user":{"displayName":"Simone Monti","photoUrl":"","userId":"05627730269189237708"}},"outputId":"866c0b76-a74c-4d6c-9a01-58e45440e838"},"source":["!pip install transformers[sentencepiece]"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting transformers[sentencepiece]\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n","\u001b[K     |████████████████████████████████| 2.3MB 7.5MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (4.41.1)\n","Collecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 52.2MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2019.12.20)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (20.9)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (4.0.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.0.12)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 52.3MB/s \n","\u001b[?25hCollecting huggingface-hub==0.0.8\n","  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (1.19.5)\n","Requirement already satisfied: protobuf; extra == \"sentencepiece\" in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.12.4)\n","Collecting sentencepiece==0.1.91; extra == \"sentencepiece\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/e2/813dff3d72df2f49554204e7e5f73a3dc0f0eb1e3958a4cad3ef3fb278b7/sentencepiece-0.1.91-cp37-cp37m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 46.8MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers[sentencepiece]) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers[sentencepiece]) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers[sentencepiece]) (3.7.4.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (1.24.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers[sentencepiece]) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers[sentencepiece]) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers[sentencepiece]) (1.0.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf; extra == \"sentencepiece\"->transformers[sentencepiece]) (57.0.0)\n","Installing collected packages: tokenizers, sacremoses, huggingface-hub, sentencepiece, transformers\n","Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 sentencepiece-0.1.91 tokenizers-0.10.3 transformers-4.6.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"A3FZ9TPfLPOy","executionInfo":{"status":"ok","timestamp":1623334901839,"user_tz":-120,"elapsed":5883,"user":{"displayName":"Simone Monti","photoUrl":"","userId":"05627730269189237708"}}},"source":["from google.colab import drive\n","\n","import numpy as np\n","import pandas as pd\n","from tqdm import *\n","\n","import tensorflow as tf\n","from tensorflow.keras.metrics import AUC\n","from tensorflow import keras\n","from keras import backend as K  #for f1\n","\n","from transformers import TFDistilBertModel, DistilBertConfig\n","from transformers import DistilBertTokenizerFast\n","\n","import matplotlib.pyplot as plt\n","\n","from sklearn.metrics import classification_report"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cgvh38JgLRLH","executionInfo":{"status":"ok","timestamp":1623334925038,"user_tz":-120,"elapsed":23203,"user":{"displayName":"Simone Monti","photoUrl":"","userId":"05627730269189237708"}},"outputId":"3b35a7ea-06d0-4c3e-84fe-040c748d35b9"},"source":["drive.mount('/content/drive', force_remount = True)\n","root_dir = '/content/drive/MyDrive/Toxic_comment_classification_Maggio_Monti/dataset/'"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AQaocjnAMpgD","executionInfo":{"status":"ok","timestamp":1623334925040,"user_tz":-120,"elapsed":24,"user":{"displayName":"Simone Monti","photoUrl":"","userId":"05627730269189237708"}}},"source":["def recall_m(y_true, y_pred):\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","    recall = true_positives / (possible_positives + K.epsilon())\n","    return recall\n","\n","def precision_m(y_true, y_pred):\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","    precision = true_positives / (predicted_positives + K.epsilon())\n","    return precision\n","\n","\n","def f1_m(y_true, y_pred):\n","    precision = precision_m(y_true, y_pred)\n","    recall = recall_m(y_true, y_pred)\n","    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"uhsVKuF7OF3E","executionInfo":{"status":"ok","timestamp":1623334925838,"user_tz":-120,"elapsed":7,"user":{"displayName":"Simone Monti","photoUrl":"","userId":"05627730269189237708"}}},"source":["params = {'MAX_LENGTH': 128,\n","          'EPOCHS': 6,\n","          'LEARNING_RATE': 5e-5,\n","          'FT_EPOCHS': 6,\n","          'OPTIMIZER': 'adam',\n","          'FT_LEARNING_RATE': 2e-5,\n","          'BATCH_SIZE': 64,\n","          'NUM_STEPS': 64,\n","          'DISTILBERT_DROPOUT': 0.2,\n","          'DISTILBERT_ATT_DROPOUT': 0.2,\n","          'LAYER_DROPOUT': 0.2,\n","          'KERNEL_INITIALIZER': 'GlorotNormal',\n","          'BIAS_INITIALIZER': 'zeros',\n","          'POS_PROBA_THRESHOLD': 0.5,          \n","          'ADDED_LAYERS': 'Dense 256, Dense 32, Dropout 0.2',\n","          'LR_SCHEDULE': '5e-5 for 6 epochs, Fine-tune w/ adam for 6 epochs @2e-5',\n","          'FREEZING': 'All DistilBERT layers frozen for 6 epochs, then unfrozen for 6',\n","          'CALLBACKS': '[early_stopping monitoring val_loss w/ patience=0]',\n","          'RANDOM_STATE':42\n","          }"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y4H7eseIOBU6","executionInfo":{"status":"ok","timestamp":1623334925839,"user_tz":-120,"elapsed":6,"user":{"displayName":"Simone Monti","photoUrl":"","userId":"05627730269189237708"}}},"source":["def build_model(transformer, max_length=params['MAX_LENGTH']):\n","    \"\"\"\"\"\"\"\"\"\n","    Template for building a model off of the BERT or DistilBERT architecture\n","    for a binary classification task.\n","    \n","    Input:\n","      - transformer:  a base Hugging Face transformer model object (BERT or DistilBERT)\n","                      with no added classification head attached.\n","      - max_length:   integer controlling the maximum number of encoded tokens \n","                      in a given sequence.\n","    \n","    Output:\n","      - model:        a compiled tf.keras.Model with added classification layers \n","                      on top of the base pre-trained model architecture.\n","    \"\"\"\"\"\"\"\"\"\n","    \n","    # Define weight initializer with a random seed to ensure reproducibility\n","    weight_initializer = tf.keras.initializers.GlorotNormal(seed=params['RANDOM_STATE']) \n","    \n","    # Define input layers\n","    input_ids_layer = tf.keras.layers.Input(shape=(max_length,), \n","                                            name='input_ids', \n","                                            dtype='int32')\n","    input_attention_layer = tf.keras.layers.Input(shape=(max_length,), \n","                                                  name='input_attention', \n","                                                  dtype='int32')\n","    \n","    # DistilBERT outputs a tuple where the first element at index 0\n","    # represents the hidden-state at the output of the model's last layer.\n","    # It is a tf.Tensor of shape (batch_size, sequence_length, hidden_size=768).\n","    last_hidden_state = transformer([input_ids_layer, input_attention_layer])[0]\n","    \n","    # We only care about DistilBERT's output for the [CLS] token, which is located\n","    # at index 0.  Splicing out the [CLS] tokens gives us 2D data.\n","    cls_token = last_hidden_state[:, 0, :]\n","    \n","    D1 = tf.keras.layers.Dropout(params['LAYER_DROPOUT'],\n","                                 seed=params['RANDOM_STATE']\n","                                )(cls_token)\n","    \n","    X = tf.keras.layers.Dense(256,\n","                              activation='relu',\n","                              kernel_initializer=weight_initializer,\n","                              bias_initializer='zeros'\n","                              )(D1)\n","    \n","    D2 = tf.keras.layers.Dropout(params['LAYER_DROPOUT'],\n","                                 seed=params['RANDOM_STATE']\n","                                )(X)\n","    \n","    X = tf.keras.layers.Dense(32,\n","                              activation='relu',\n","                              kernel_initializer=weight_initializer,\n","                              bias_initializer='zeros'\n","                              )(D2)\n","    \n","    D3 = tf.keras.layers.Dropout(params['LAYER_DROPOUT'],\n","                                 seed=params['RANDOM_STATE']\n","                                )(X)\n","    \n","    # Define a single node that makes up the output layer (for binary classification)\n","    output = tf.keras.layers.Dense(6, \n","                                   activation='sigmoid',\n","                                   kernel_initializer=weight_initializer,  # CONSIDER USING CONSTRAINT\n","                                   bias_initializer='zeros'\n","                                   )(D3)\n","    \n","    # Define the model\n","    model = tf.keras.Model([input_ids_layer, input_attention_layer], output)\n","    \n","    auc_score = AUC(multi_label=True)\n","    # Compile the model\n","    model.compile(tf.keras.optimizers.Adam(lr=params['LEARNING_RATE']), \n","                  loss='binary_crossentropy',\n","                  metrics=[auc_score, f1_m])\n","    \n","    return model"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M3fDzYk8LUpS","executionInfo":{"elapsed":2415,"status":"ok","timestamp":1622497015592,"user":{"displayName":"Vittorio Maggio","photoUrl":"","userId":"16660645013264801501"},"user_tz":-120},"outputId":"986e22ec-cd0d-408d-fc99-2403c438e235"},"source":["# The bare, pretrained DistilBERT transformer model outputting raw hidden-states \n","# and without any specific head on top.\n","config = DistilBertConfig(dropout=params['DISTILBERT_DROPOUT'], \n","                          attention_dropout=params['DISTILBERT_ATT_DROPOUT'], \n","                          output_hidden_states=True)\n","distilBERT = TFDistilBertModel.from_pretrained('distilbert-base-uncased', config=config)\n","\n","# Build model\n","model = build_model(distilBERT)\n","model.load_weights('/content/drive/MyDrive/Toxic_comment_classification_Maggio_Monti/models/model_freeze_w.h5')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_transform', 'activation_13', 'vocab_projector', 'vocab_layer_norm']\n","- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"N0GxPNGpMmMg"},"source":["from transformers import AutoTokenizer\n","tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n","\n","import pandas as pd\n","test = pd.read_csv(root_dir + 'dataset_clean/test_clean.csv', index_col=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"G9IC67fgXEqp","executionInfo":{"elapsed":516,"status":"ok","timestamp":1622497058772,"user":{"displayName":"Vittorio Maggio","photoUrl":"","userId":"16660645013264801501"},"user_tz":-120},"outputId":"8154f986-aff7-4eab-d6c7-185797c7c8c8"},"source":["test"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>toxic</th>\n","      <th>severe_toxic</th>\n","      <th>obscene</th>\n","      <th>threat</th>\n","      <th>insult</th>\n","      <th>identity_hate</th>\n","      <th>comment_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0001ea8717f6de06</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>thank you for understanding i think very highl...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>000247e83dcc1211</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>dear god this site is horrible</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0002f87b16116a7f</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>somebody will invariably try to add religion r...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0003e1cccfd5a40a</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>it says it right there that it is a type the t...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>00059ace3e3e9a53</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>before adding a new product to the list make s...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>63973</th>\n","      <td>fff8f64043129fa2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>jerome i see you never got around to this im n...</td>\n","    </tr>\n","    <tr>\n","      <th>63974</th>\n","      <td>fff9d70fe0722906</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>lucky bastard http wikimediafoundation org wik...</td>\n","    </tr>\n","    <tr>\n","      <th>63975</th>\n","      <td>fffa8a11c4378854</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>shame on you all you want to speak about gays ...</td>\n","    </tr>\n","    <tr>\n","      <th>63976</th>\n","      <td>fffac2a094c8e0e2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>mel gibson is a nazi bitch who makes shitty mo...</td>\n","    </tr>\n","    <tr>\n","      <th>63977</th>\n","      <td>fffb5451268fb5ba</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>unicorn lair discovery supposedly a unicorn la...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>63978 rows × 8 columns</p>\n","</div>"],"text/plain":["                     id  ...                                       comment_text\n","0      0001ea8717f6de06  ...  thank you for understanding i think very highl...\n","1      000247e83dcc1211  ...                    dear god this site is horrible \n","2      0002f87b16116a7f  ...  somebody will invariably try to add religion r...\n","3      0003e1cccfd5a40a  ...  it says it right there that it is a type the t...\n","4      00059ace3e3e9a53  ...  before adding a new product to the list make s...\n","...                 ...  ...                                                ...\n","63973  fff8f64043129fa2  ...  jerome i see you never got around to this im n...\n","63974  fff9d70fe0722906  ...  lucky bastard http wikimediafoundation org wik...\n","63975  fffa8a11c4378854  ...  shame on you all you want to speak about gays ...\n","63976  fffac2a094c8e0e2  ...  mel gibson is a nazi bitch who makes shitty mo...\n","63977  fffb5451268fb5ba  ...  unicorn lair discovery supposedly a unicorn la...\n","\n","[63978 rows x 8 columns]"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"WRM-Y0HFQrXj"},"source":["x_test = test['comment_text'].values\n","y_test = test.drop([\"comment_text\", 'id'] , axis=1)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mPVCQqH0U--b","executionInfo":{"elapsed":845,"status":"ok","timestamp":1622497078246,"user":{"displayName":"Vittorio Maggio","photoUrl":"","userId":"16660645013264801501"},"user_tz":-120},"outputId":"9944fc1a-17f8-41f9-9d46-7bcaaf885857"},"source":["x_test"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['thank you for understanding i think very highly of you and would not revert without discussion ',\n","       'dear god this site is horrible ',\n","       'somebody will invariably try to add religion really you mean the way people have invariably kept adding religion to the samuel beckett infobox and why do you bother bringing up the long dead completely non existent influences issue youre just flailing making up crap on the fly for comparison the only explicit acknowledgement in the entire amos oz article that he is personally jewish is in the categories ',\n","       ...,\n","       'shame on you all you want to speak about gays and not about romanians ',\n","       'mel gibson is a nazi bitch who makes shitty movies he has so much buttsex that his asshole is now big enough to be considered a country ',\n","       'unicorn lair discovery supposedly a unicorn lair has been discovered in pyongyang north korea the lair is supposedly associated with king dongmyeong of goguryeo who supposedly rode a unicorn it should be added but i cant quite find where to insert it '],\n","      dtype=object)"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cfsmSuGOPHPr","executionInfo":{"elapsed":15899,"status":"ok","timestamp":1622497111818,"user":{"displayName":"Vittorio Maggio","photoUrl":"","userId":"16660645013264801501"},"user_tz":-120},"outputId":"38b18c87-b8c6-4fa9-fe42-b2dc036eebe9"},"source":["padded_ids_test = []\n","mask_ids_test = []\n","for i in tqdm(range(len(x_test))):\n","  encoding = tokenizer(str(x_test[i]), max_length=128 , padding =\"max_length\", truncation=True)\n","  input_ids , attention_id = encoding[\"input_ids\"] , encoding[\"attention_mask\"] \n","  padded_ids_test.append(input_ids)\n","  mask_ids_test.append(attention_id)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 63978/63978 [00:16<00:00, 3838.14it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"UO6arOZfXzm1"},"source":["test_id = np.array(padded_ids_test)\n","test_mask = np.array(mask_ids_test)\n","\n","test_id = np.squeeze(test_id) \n","test_mask =  np.squeeze(test_mask) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w2O8HTJbXUh3","executionInfo":{"elapsed":267629,"status":"ok","timestamp":1622497670222,"user":{"displayName":"Vittorio Maggio","photoUrl":"","userId":"16660645013264801501"},"user_tz":-120},"outputId":"6bb5f887-1309-4643-a260-02e085fb0b1c"},"source":["y_pred = model.predict([test_id, test_mask])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pgcUxqtpbEbR"},"source":["y_pred = y_pred >= 0.5"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WtFi9vEnZ048","executionInfo":{"elapsed":586,"status":"ok","timestamp":1622497856714,"user":{"displayName":"Vittorio Maggio","photoUrl":"","userId":"16660645013264801501"},"user_tz":-120},"outputId":"f3cd2055-5a3b-4f9c-fcfe-ac5f2c440c5a"},"source":["print(classification_report(y_test, y_pred, zero_division=1))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.63      0.59      0.61      6090\n","           1       0.34      0.34      0.34       367\n","           2       0.67      0.57      0.62      3691\n","           3       1.00      0.00      0.00       211\n","           4       0.65      0.46      0.54      3427\n","           5       1.00      0.00      0.00       712\n","\n","   micro avg       0.64      0.51      0.57     14498\n","   macro avg       0.72      0.33      0.35     14498\n","weighted avg       0.66      0.51      0.55     14498\n"," samples avg       0.96      0.95      0.92     14498\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UGiMGhcNZwia","executionInfo":{"elapsed":278573,"status":"ok","timestamp":1622498189082,"user":{"displayName":"Vittorio Maggio","photoUrl":"","userId":"16660645013264801501"},"user_tz":-120},"outputId":"e6d8997e-a423-4306-c710-e3f073771ea5"},"source":["model.evaluate([test_id, test_mask], y_test, return_dict=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","2000/2000 [==============================] - 278s 137ms/step - loss: 0.0798 - auc_1: 0.9463 - f1_m: 0.4871\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["{'auc_1': 0.9462966918945312,\n"," 'f1_m': 0.48706507682800293,\n"," 'loss': 0.07981007546186447}"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"markdown","metadata":{"id":"gWfBZZ9-dohi"},"source":["# Fine Tune"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H4OoVkBvaPFq","executionInfo":{"elapsed":6879,"status":"ok","timestamp":1622498792798,"user":{"displayName":"Vittorio Maggio","photoUrl":"","userId":"16660645013264801501"},"user_tz":-120},"outputId":"1307a48c-2fe5-47c1-f3a0-d2f1caaee4ec"},"source":["# Build model\n","model = build_model(distilBERT)\n","model.load_weights('/content/drive/MyDrive/Toxic_comment_classification_Maggio_Monti/models/model_UNfreeze_w.h5')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R6GB6LSbdrd6","executionInfo":{"elapsed":323769,"status":"ok","timestamp":1622499130513,"user":{"displayName":"Vittorio Maggio","photoUrl":"","userId":"16660645013264801501"},"user_tz":-120},"outputId":"6f8a6fb4-5e60-4820-d725-391a2bfa9ef5"},"source":["y_pred = model.predict([test_id, test_mask]) > 0.5"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0ZdhknxydzWQ","executionInfo":{"elapsed":632,"status":"ok","timestamp":1622499132719,"user":{"displayName":"Vittorio Maggio","photoUrl":"","userId":"16660645013264801501"},"user_tz":-120},"outputId":"9323489c-eaf1-44b0-d807-f179cb11b085"},"source":["print(classification_report(y_test, y_pred, zero_division=1))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.54      0.89      0.68      6090\n","           1       0.37      0.47      0.42       367\n","           2       0.60      0.81      0.69      3691\n","           3       0.56      0.54      0.55       211\n","           4       0.66      0.72      0.69      3427\n","           5       0.60      0.61      0.60       712\n","\n","   micro avg       0.58      0.80      0.67     14498\n","   macro avg       0.56      0.67      0.60     14498\n","weighted avg       0.58      0.80      0.67     14498\n"," samples avg       0.92      0.98      0.91     14498\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"nNc8zLd2d0hP","outputId":"2f19f1fc-cc0c-44e5-97db-6aa001439320"},"source":["model.evaluate([test_id, test_mask], y_test, return_dict=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","2000/2000 [==============================] - 287s 142ms/step - loss: 0.0734 - auc_2: 0.9731 - f1_m: 0.6181\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["{'auc_2': 0.9731385707855225,\n"," 'f1_m': 0.61812424659729,\n"," 'loss': 0.07336844503879547}"]},"metadata":{"tags":[]},"execution_count":0}]}]}