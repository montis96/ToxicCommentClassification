{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6874,"status":"ok","timestamp":1622496298264,"user":{"displayName":"Vittorio Maggio","photoUrl":"","userId":"16660645013264801501"},"user_tz":-120},"id":"BXyQvCqdLNAw","outputId":"ceeb4793-fcc7-4646-d4f8-f88c8f6732f0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting transformers[sentencepiece]\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n","\u001b[K     |████████████████████████████████| 2.3MB 7.3MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (20.9)\n","Collecting tokenizers\u003c0.11,\u003e=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 47.1MB/s \n","\u001b[?25hCollecting huggingface-hub==0.0.8\n","  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n","Requirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (4.41.1)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (1.19.5)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 54.8MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata; python_version \u003c \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (4.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.0.12)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2.23.0)\n","Requirement already satisfied: protobuf; extra == \"sentencepiece\" in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.12.4)\n","Collecting sentencepiece==0.1.91; extra == \"sentencepiece\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/e2/813dff3d72df2f49554204e7e5f73a3dc0f0eb1e3958a4cad3ef3fb278b7/sentencepiece-0.1.91-cp37-cp37m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 40.6MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging-\u003etransformers[sentencepiece]) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers[sentencepiece]) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers[sentencepiece]) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers[sentencepiece]) (7.1.2)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version \u003c \"3.8\"-\u003etransformers[sentencepiece]) (3.4.1)\n","Requirement already satisfied: typing-extensions\u003e=3.6.4; python_version \u003c \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version \u003c \"3.8\"-\u003etransformers[sentencepiece]) (3.7.4.3)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers[sentencepiece]) (1.24.3)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers[sentencepiece]) (2.10)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers[sentencepiece]) (2020.12.5)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers[sentencepiece]) (3.0.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf; extra == \"sentencepiece\"-\u003etransformers[sentencepiece]) (56.1.0)\n","Installing collected packages: tokenizers, huggingface-hub, sacremoses, sentencepiece, transformers\n","Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 sentencepiece-0.1.91 tokenizers-0.10.3 transformers-4.6.1\n"]}],"source":["!pip install transformers[sentencepiece]"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":4785,"status":"ok","timestamp":1622496303047,"user":{"displayName":"Vittorio Maggio","photoUrl":"","userId":"16660645013264801501"},"user_tz":-120},"id":"A3FZ9TPfLPOy"},"outputs":[],"source":["from google.colab import drive\n","\n","import numpy as np\n","import pandas as pd\n","from tqdm import *\n","\n","import tensorflow as tf\n","from tensorflow.keras.metrics import AUC\n","from tensorflow import keras\n","from keras import backend as K  #for f1\n","\n","from transformers import TFDistilBertModel, DistilBertConfig\n","from transformers import DistilBertTokenizerFast\n","\n","import matplotlib.pyplot as plt\n","\n","from sklearn.metrics import classification_report"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16181,"status":"ok","timestamp":1622496319227,"user":{"displayName":"Vittorio Maggio","photoUrl":"","userId":"16660645013264801501"},"user_tz":-120},"id":"cgvh38JgLRLH","outputId":"427419a9-5b04-4f9a-b8b0-0b9ccc283e53"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["drive.mount('/content/drive', force_remount = True)\n","root_dir = '/content/drive/MyDrive/Toxic_comment_classification_Maggio_Monti/dataset/'"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1622496319227,"user":{"displayName":"Vittorio Maggio","photoUrl":"","userId":"16660645013264801501"},"user_tz":-120},"id":"AQaocjnAMpgD"},"outputs":[],"source":["def recall_m(y_true, y_pred):\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","    recall = true_positives / (possible_positives + K.epsilon())\n","    return recall\n","\n","def precision_m(y_true, y_pred):\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","    precision = true_positives / (predicted_positives + K.epsilon())\n","    return precision\n","\n","\n","def f1_m(y_true, y_pred):\n","    precision = precision_m(y_true, y_pred)\n","    recall = recall_m(y_true, y_pred)\n","    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1622496319228,"user":{"displayName":"Vittorio Maggio","photoUrl":"","userId":"16660645013264801501"},"user_tz":-120},"id":"uhsVKuF7OF3E"},"outputs":[],"source":["params = {'MAX_LENGTH': 128,\n","          'EPOCHS': 6,\n","          'LEARNING_RATE': 5e-5,\n","          'FT_EPOCHS': 6,\n","          'OPTIMIZER': 'adam',\n","          'FT_LEARNING_RATE': 2e-5,\n","          'BATCH_SIZE': 64,\n","          'NUM_STEPS': 64,\n","          'DISTILBERT_DROPOUT': 0.2,\n","          'DISTILBERT_ATT_DROPOUT': 0.2,\n","          'LAYER_DROPOUT': 0.2,\n","          'KERNEL_INITIALIZER': 'GlorotNormal',\n","          'BIAS_INITIALIZER': 'zeros',\n","          'POS_PROBA_THRESHOLD': 0.5,          \n","          'ADDED_LAYERS': 'Dense 256, Dense 32, Dropout 0.2',\n","          'LR_SCHEDULE': '5e-5 for 6 epochs, Fine-tune w/ adam for 6 epochs @2e-5',\n","          'FREEZING': 'All DistilBERT layers frozen for 6 epochs, then unfrozen for 6',\n","          'CALLBACKS': '[early_stopping monitoring val_loss w/ patience=0]',\n","          'RANDOM_STATE':42\n","          }"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1622496319229,"user":{"displayName":"Vittorio Maggio","photoUrl":"","userId":"16660645013264801501"},"user_tz":-120},"id":"Y4H7eseIOBU6"},"outputs":[],"source":["def build_model(transformer, max_length=params['MAX_LENGTH']):\n","    \"\"\"\"\"\"\"\"\"\n","    Template for building a model off of the BERT or DistilBERT architecture\n","    for a binary classification task.\n","    \n","    Input:\n","      - transformer:  a base Hugging Face transformer model object (BERT or DistilBERT)\n","                      with no added classification head attached.\n","      - max_length:   integer controlling the maximum number of encoded tokens \n","                      in a given sequence.\n","    \n","    Output:\n","      - model:        a compiled tf.keras.Model with added classification layers \n","                      on top of the base pre-trained model architecture.\n","    \"\"\"\"\"\"\"\"\"\n","    \n","    # Define weight initializer with a random seed to ensure reproducibility\n","    weight_initializer = tf.keras.initializers.GlorotNormal(seed=params['RANDOM_STATE']) \n","    \n","    # Define input layers\n","    input_ids_layer = tf.keras.layers.Input(shape=(max_length,), \n","                                            name='input_ids', \n","                                            dtype='int32')\n","    input_attention_layer = tf.keras.layers.Input(shape=(max_length,), \n","                                                  name='input_attention', \n","                                                  dtype='int32')\n","    \n","    # DistilBERT outputs a tuple where the first element at index 0\n","    # represents the hidden-state at the output of the model's last layer.\n","    # It is a tf.Tensor of shape (batch_size, sequence_length, hidden_size=768).\n","    last_hidden_state = transformer([input_ids_layer, input_attention_layer])[0]\n","    \n","    # We only care about DistilBERT's output for the [CLS] token, which is located\n","    # at index 0.  Splicing out the [CLS] tokens gives us 2D data.\n","    cls_token = last_hidden_state[:, 0, :]\n","    \n","    D1 = tf.keras.layers.Dropout(params['LAYER_DROPOUT'],\n","                                 seed=params['RANDOM_STATE']\n","                                )(cls_token)\n","    \n","    X = tf.keras.layers.Dense(256,\n","                              activation='relu',\n","                              kernel_initializer=weight_initializer,\n","                              bias_initializer='zeros'\n","                              )(D1)\n","    \n","    D2 = tf.keras.layers.Dropout(params['LAYER_DROPOUT'],\n","                                 seed=params['RANDOM_STATE']\n","                                )(X)\n","    \n","    X = tf.keras.layers.Dense(32,\n","                              activation='relu',\n","                              kernel_initializer=weight_initializer,\n","                              bias_initializer='zeros'\n","                              )(D2)\n","    \n","    D3 = tf.keras.layers.Dropout(params['LAYER_DROPOUT'],\n","                                 seed=params['RANDOM_STATE']\n","                                )(X)\n","    \n","    # Define a single node that makes up the output layer (for binary classification)\n","    output = tf.keras.layers.Dense(6, \n","                                   activation='sigmoid',\n","                                   kernel_initializer=weight_initializer,  # CONSIDER USING CONSTRAINT\n","                                   bias_initializer='zeros'\n","                                   )(D3)\n","    \n","    # Define the model\n","    model = tf.keras.Model([input_ids_layer, input_attention_layer], output)\n","    \n","    auc_score = AUC(multi_label=True)\n","    # Compile the model\n","    model.compile(tf.keras.optimizers.Adam(lr=params['LEARNING_RATE']), \n","                  loss='binary_crossentropy',\n","                  metrics=[auc_score, f1_m])\n","    \n","    return model"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2415,"status":"ok","timestamp":1622497015592,"user":{"displayName":"Vittorio Maggio","photoUrl":"","userId":"16660645013264801501"},"user_tz":-120},"id":"M3fDzYk8LUpS","outputId":"986e22ec-cd0d-408d-fc99-2403c438e235"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_transform', 'activation_13', 'vocab_projector', 'vocab_layer_norm']\n","- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"]},{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"]}],"source":["# The bare, pretrained DistilBERT transformer model outputting raw hidden-states \n","# and without any specific head on top.\n","config = DistilBertConfig(dropout=params['DISTILBERT_DROPOUT'], \n","                          attention_dropout=params['DISTILBERT_ATT_DROPOUT'], \n","                          output_hidden_states=True)\n","distilBERT = TFDistilBertModel.from_pretrained('distilbert-base-uncased', config=config)\n","\n","# Build model\n","model = build_model(distilBERT)\n","model.load_weights('/content/drive/MyDrive/Toxic_comment_classification_Maggio_Monti/models/model_freeze_w.h5')"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":2777,"status":"ok","timestamp":1622497039277,"user":{"displayName":"Vittorio Maggio","photoUrl":"","userId":"16660645013264801501"},"user_tz":-120},"id":"N0GxPNGpMmMg"},"outputs":[],"source":["from transformers import AutoTokenizer\n","tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n","\n","import pandas as pd\n","test = pd.read_csv(root_dir + 'dataset_clean/test_clean.csv', index_col=0)"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"executionInfo":{"elapsed":516,"status":"ok","timestamp":1622497058772,"user":{"displayName":"Vittorio Maggio","photoUrl":"","userId":"16660645013264801501"},"user_tz":-120},"id":"G9IC67fgXEqp","outputId":"8154f986-aff7-4eab-d6c7-185797c7c8c8"},"outputs":[{"data":{"text/html":["\u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eid\u003c/th\u003e\n","      \u003cth\u003etoxic\u003c/th\u003e\n","      \u003cth\u003esevere_toxic\u003c/th\u003e\n","      \u003cth\u003eobscene\u003c/th\u003e\n","      \u003cth\u003ethreat\u003c/th\u003e\n","      \u003cth\u003einsult\u003c/th\u003e\n","      \u003cth\u003eidentity_hate\u003c/th\u003e\n","      \u003cth\u003ecomment_text\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e0001ea8717f6de06\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003ethank you for understanding i think very highl...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e000247e83dcc1211\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003edear god this site is horrible\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e0002f87b16116a7f\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003esomebody will invariably try to add religion r...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e0003e1cccfd5a40a\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eit says it right there that it is a type the t...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e00059ace3e3e9a53\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003ebefore adding a new product to the list make s...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e...\u003c/th\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e63973\u003c/th\u003e\n","      \u003ctd\u003efff8f64043129fa2\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003ejerome i see you never got around to this im n...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e63974\u003c/th\u003e\n","      \u003ctd\u003efff9d70fe0722906\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003elucky bastard http wikimediafoundation org wik...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e63975\u003c/th\u003e\n","      \u003ctd\u003efffa8a11c4378854\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eshame on you all you want to speak about gays ...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e63976\u003c/th\u003e\n","      \u003ctd\u003efffac2a094c8e0e2\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003emel gibson is a nazi bitch who makes shitty mo...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e63977\u003c/th\u003e\n","      \u003ctd\u003efffb5451268fb5ba\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eunicorn lair discovery supposedly a unicorn la...\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003cp\u003e63978 rows × 8 columns\u003c/p\u003e\n","\u003c/div\u003e"],"text/plain":["                     id  ...                                       comment_text\n","0      0001ea8717f6de06  ...  thank you for understanding i think very highl...\n","1      000247e83dcc1211  ...                    dear god this site is horrible \n","2      0002f87b16116a7f  ...  somebody will invariably try to add religion r...\n","3      0003e1cccfd5a40a  ...  it says it right there that it is a type the t...\n","4      00059ace3e3e9a53  ...  before adding a new product to the list make s...\n","...                 ...  ...                                                ...\n","63973  fff8f64043129fa2  ...  jerome i see you never got around to this im n...\n","63974  fff9d70fe0722906  ...  lucky bastard http wikimediafoundation org wik...\n","63975  fffa8a11c4378854  ...  shame on you all you want to speak about gays ...\n","63976  fffac2a094c8e0e2  ...  mel gibson is a nazi bitch who makes shitty mo...\n","63977  fffb5451268fb5ba  ...  unicorn lair discovery supposedly a unicorn la...\n","\n","[63978 rows x 8 columns]"]},"execution_count":22,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["test"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1622497074053,"user":{"displayName":"Vittorio Maggio","photoUrl":"","userId":"16660645013264801501"},"user_tz":-120},"id":"WRM-Y0HFQrXj"},"outputs":[],"source":["x_test = test['comment_text'].values\n","y_test = test.drop([\"comment_text\", 'id'] , axis=1)\n"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":845,"status":"ok","timestamp":1622497078246,"user":{"displayName":"Vittorio Maggio","photoUrl":"","userId":"16660645013264801501"},"user_tz":-120},"id":"mPVCQqH0U--b","outputId":"9944fc1a-17f8-41f9-9d46-7bcaaf885857"},"outputs":[{"data":{"text/plain":["array(['thank you for understanding i think very highly of you and would not revert without discussion ',\n","       'dear god this site is horrible ',\n","       'somebody will invariably try to add religion really you mean the way people have invariably kept adding religion to the samuel beckett infobox and why do you bother bringing up the long dead completely non existent influences issue youre just flailing making up crap on the fly for comparison the only explicit acknowledgement in the entire amos oz article that he is personally jewish is in the categories ',\n","       ...,\n","       'shame on you all you want to speak about gays and not about romanians ',\n","       'mel gibson is a nazi bitch who makes shitty movies he has so much buttsex that his asshole is now big enough to be considered a country ',\n","       'unicorn lair discovery supposedly a unicorn lair has been discovered in pyongyang north korea the lair is supposedly associated with king dongmyeong of goguryeo who supposedly rode a unicorn it should be added but i cant quite find where to insert it '],\n","      dtype=object)"]},"execution_count":25,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["x_test"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15899,"status":"ok","timestamp":1622497111818,"user":{"displayName":"Vittorio Maggio","photoUrl":"","userId":"16660645013264801501"},"user_tz":-120},"id":"cfsmSuGOPHPr","outputId":"38b18c87-b8c6-4fa9-fe42-b2dc036eebe9"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 63978/63978 [00:16\u003c00:00, 3838.14it/s]\n"]}],"source":["padded_ids_test = []\n","mask_ids_test = []\n","for i in tqdm(range(len(x_test))):\n","  encoding = tokenizer(str(x_test[i]), max_length=128 , padding =\"max_length\", truncation=True)\n","  input_ids , attention_id = encoding[\"input_ids\"] , encoding[\"attention_mask\"] \n","  padded_ids_test.append(input_ids)\n","  mask_ids_test.append(attention_id)"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":798,"status":"ok","timestamp":1622497293203,"user":{"displayName":"Vittorio Maggio","photoUrl":"","userId":"16660645013264801501"},"user_tz":-120},"id":"UO6arOZfXzm1"},"outputs":[],"source":["test_id = np.array(padded_ids_test)\n","test_mask = np.array(mask_ids_test)\n","\n","test_id = np.squeeze(test_id) \n","test_mask =  np.squeeze(test_mask) "]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":267629,"status":"ok","timestamp":1622497670222,"user":{"displayName":"Vittorio Maggio","photoUrl":"","userId":"16660645013264801501"},"user_tz":-120},"id":"w2O8HTJbXUh3","outputId":"6bb5f887-1309-4643-a260-02e085fb0b1c"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"]}],"source":["y_pred = model.predict([test_id, test_mask])"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":801,"status":"ok","timestamp":1622497747752,"user":{"displayName":"Vittorio Maggio","photoUrl":"","userId":"16660645013264801501"},"user_tz":-120},"id":"pgcUxqtpbEbR"},"outputs":[],"source":["y_pred = y_pred \u003e= 0.5"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":586,"status":"ok","timestamp":1622497856714,"user":{"displayName":"Vittorio Maggio","photoUrl":"","userId":"16660645013264801501"},"user_tz":-120},"id":"WtFi9vEnZ048","outputId":"f3cd2055-5a3b-4f9c-fcfe-ac5f2c440c5a"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.63      0.59      0.61      6090\n","           1       0.34      0.34      0.34       367\n","           2       0.67      0.57      0.62      3691\n","           3       1.00      0.00      0.00       211\n","           4       0.65      0.46      0.54      3427\n","           5       1.00      0.00      0.00       712\n","\n","   micro avg       0.64      0.51      0.57     14498\n","   macro avg       0.72      0.33      0.35     14498\n","weighted avg       0.66      0.51      0.55     14498\n"," samples avg       0.96      0.95      0.92     14498\n","\n"]}],"source":["print(classification_report(y_test, y_pred, zero_division=1))"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":278573,"status":"ok","timestamp":1622498189082,"user":{"displayName":"Vittorio Maggio","photoUrl":"","userId":"16660645013264801501"},"user_tz":-120},"id":"UGiMGhcNZwia","outputId":"e6d8997e-a423-4306-c710-e3f073771ea5"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","2000/2000 [==============================] - 278s 137ms/step - loss: 0.0798 - auc_1: 0.9463 - f1_m: 0.4871\n"]},{"data":{"text/plain":["{'auc_1': 0.9462966918945312,\n"," 'f1_m': 0.48706507682800293,\n"," 'loss': 0.07981007546186447}"]},"execution_count":36,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["model.evaluate([test_id, test_mask], y_test, return_dict=True)"]},{"cell_type":"markdown","metadata":{"id":"gWfBZZ9-dohi"},"source":["# Fine Tune"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6879,"status":"ok","timestamp":1622498792798,"user":{"displayName":"Vittorio Maggio","photoUrl":"","userId":"16660645013264801501"},"user_tz":-120},"id":"H4OoVkBvaPFq","outputId":"1307a48c-2fe5-47c1-f3a0-d2f1caaee4ec"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"]}],"source":["# Build model\n","model = build_model(distilBERT)\n","model.load_weights('/content/drive/MyDrive/Toxic_comment_classification_Maggio_Monti/models/model_UNfreeze_w.h5')"]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":323769,"status":"ok","timestamp":1622499130513,"user":{"displayName":"Vittorio Maggio","photoUrl":"","userId":"16660645013264801501"},"user_tz":-120},"id":"R6GB6LSbdrd6","outputId":"6f8a6fb4-5e60-4820-d725-391a2bfa9ef5"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"]}],"source":["y_pred = model.predict([test_id, test_mask]) \u003e 0.5"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":632,"status":"ok","timestamp":1622499132719,"user":{"displayName":"Vittorio Maggio","photoUrl":"","userId":"16660645013264801501"},"user_tz":-120},"id":"0ZdhknxydzWQ","outputId":"9323489c-eaf1-44b0-d807-f179cb11b085"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.54      0.89      0.68      6090\n","           1       0.37      0.47      0.42       367\n","           2       0.60      0.81      0.69      3691\n","           3       0.56      0.54      0.55       211\n","           4       0.66      0.72      0.69      3427\n","           5       0.60      0.61      0.60       712\n","\n","   micro avg       0.58      0.80      0.67     14498\n","   macro avg       0.56      0.67      0.60     14498\n","weighted avg       0.58      0.80      0.67     14498\n"," samples avg       0.92      0.98      0.91     14498\n","\n"]}],"source":["print(classification_report(y_test, y_pred, zero_division=1))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"nNc8zLd2d0hP"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","2000/2000 [==============================] - 287s 142ms/step - loss: 0.0734 - auc_2: 0.9731 - f1_m: 0.6181\n"]},{"data":{"text/plain":["{'auc_2': 0.9731385707855225,\n"," 'f1_m': 0.61812424659729,\n"," 'loss': 0.07336844503879547}"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["model.evaluate([test_id, test_mask], y_test, return_dict=True)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"DistilBERT_evaluation.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}